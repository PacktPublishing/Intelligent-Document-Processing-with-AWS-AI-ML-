{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bb0ad38",
   "metadata": {},
   "source": [
    "# Intelligent Document Processing Classification\n",
    "Understanding Document classification with Amazon Comprehend custom classifier\n",
    "Sometimes we receive many documents as a single package, and we need to process each document individually to derive insights from it as per its business requirement. To achieve this, one of the major task is to categorize and index different types of documents. This later helps in accurate extraction of information putting business specific requirements. This process of categorizing the documents into its category is known as Document Classification.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4813651",
   "metadata": {},
   "source": [
    "# Prepare for Document Classification\n",
    "In this lab we will walk you through an hands-on lab on document classification using Amazon Comprehend\n",
    "Custom Classifier. We will use Amazon Textract to first extract the text out of our documents and then label them and then use the data for training our Amazon comprehend custom classifier.\n",
    "\n",
    "In this notebook we will - \n",
    "\n",
    "- [Step 1: Setup notebook and upload sample documents to Amazon S3](#step1)\n",
    "- [Step 2: Extract text from sample documents using Amazon Textract](#step2)\n",
    "- [Step 3: Label the extracted data and prepare a CSV training dataset](#step3)\n",
    "- [Step 4: Create Amazon Comprehend Classification training job](#step4)\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a20489",
   "metadata": {},
   "source": [
    "# Step 1: Setup notebook and upload  sample documents to Amazon S3 <a id=\"step1\"></a>\n",
    "\n",
    "In this step, we will import some necessary libraries that will be used throughout this notebook. We will then upload all the documents from the `/classification-training-dataset` folder to SageMaker's default bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e3f4e22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: textract-trp in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (0.1.3)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install textract-trp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dd59c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker role is: arn:aws:iam::044573436347:role/text-cm-SagemakerRole-SXXWU3NUWVCX\n",
      "Default SageMaker Bucket: s3://sagemaker-us-east-1-044573436347\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import botocore\n",
    "import sagemaker\n",
    "import time\n",
    "import os\n",
    "import os.path\n",
    "import json\n",
    "import datetime\n",
    "import io\n",
    "import uuid\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pytz import timezone\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import multiprocessing as mp\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Document\n",
    "from pprint import pprint\n",
    "from IPython.display import Image, display, HTML, JSON, IFrame\n",
    "from PIL import Image as PImage, ImageDraw\n",
    "\n",
    "\n",
    "# variables\n",
    "data_bucket = sagemaker.Session().default_bucket()\n",
    "region = boto3.session.Session().region_name\n",
    "\n",
    "os.environ[\"BUCKET\"] = data_bucket\n",
    "os.environ[\"REGION\"] = region\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "print(f\"SageMaker role is: {role}\\nDefault SageMaker Bucket: s3://{data_bucket}\")\n",
    "\n",
    "s3=boto3.client('s3')\n",
    "textract = boto3.client('textract', region_name=region)\n",
    "comprehend=boto3.client('comprehend', region_name=region)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b7cace",
   "metadata": {},
   "source": [
    "### Upload sample data to S3 bucket\n",
    "\n",
    "The sample documents are in `/classification-training-dataset` directory. For this workshop, we will be using sample paystubs, bank statements, and receipts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "31edc955",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Upload images to S3 bucket:\n",
    "#!tar -zxvf classification-training-dataset.tar.gz\n",
    "!aws s3 cp classification-training-dataset s3://{data_bucket}/train --recursive --only-show-errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8d623251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_s3_bucket_items(bucket, prefix, start_after):\n",
    "    list_items=[]\n",
    "    \n",
    "    s3=boto3.client('s3')\n",
    "    paginator = s3.get_paginator('list_objects_v2')\n",
    "    operation_parameters = {'Bucket': bucket,\n",
    "                            'Prefix': prefix,\n",
    "                            'StartAfter':start_after}\n",
    "    page_iterator = paginator.paginate(**operation_parameters)\n",
    "    for page in page_iterator:\n",
    "        \n",
    "        for item in page['Contents']:\n",
    "            list_items.append(item['Key'])\n",
    "    \n",
    "    names=list(set([os.path.dirname(x)+'/' for x in list_items]))\n",
    "    images=[x for x in list_items if x not in names and '.ipynb_checkpoints' not in x ]\n",
    "    names=[x.replace(prefix,'').strip('/') for x in names if  '.ipynb_checkpoints' not in x]\n",
    "    names=[\"receipt-training\", \"invoice-dataset\"]\n",
    "    return list_items, names, images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "31d92712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['receipt-training', 'invoice-dataset'],\n",
       " ['train/invoice-dataset/invoice_70.pdf',\n",
       "  'train/invoice-dataset/invoice_71.pdf',\n",
       "  'train/invoice-dataset/invoice_72.pdf',\n",
       "  'train/invoice-dataset/invoice_73.pdf',\n",
       "  'train/invoice-dataset/invoice_74.pdf',\n",
       "  'train/invoice-dataset/invoice_75.pdf',\n",
       "  'train/invoice-dataset/invoice_76.pdf',\n",
       "  'train/invoice-dataset/invoice_77.pdf',\n",
       "  'train/invoice-dataset/invoice_78.pdf',\n",
       "  'train/invoice-dataset/invoice_79.pdf',\n",
       "  'train/invoice-dataset/invoice_80.pdf',\n",
       "  'train/invoice-dataset/invoice_81.pdf',\n",
       "  'train/invoice-dataset/invoice_82.pdf',\n",
       "  'train/invoice-dataset/invoice_83.pdf',\n",
       "  'train/invoice-dataset/invoice_84.pdf',\n",
       "  'train/invoice-dataset/invoice_85.pdf',\n",
       "  'train/invoice-dataset/invoice_86.pdf',\n",
       "  'train/invoice-dataset/invoice_87.pdf',\n",
       "  'train/invoice-dataset/invoice_88.pdf',\n",
       "  'train/invoice-dataset/invoice_89.pdf',\n",
       "  'train/invoice-dataset/invoice_90.pdf',\n",
       "  'train/invoice-dataset/invoice_91.pdf',\n",
       "  'train/invoice-dataset/invoice_92.pdf',\n",
       "  'train/invoice-dataset/invoice_93.pdf',\n",
       "  'train/invoice-dataset/invoice_94.pdf',\n",
       "  'train/invoice-dataset/invoice_95.pdf',\n",
       "  'train/invoice-dataset/invoice_96.pdf',\n",
       "  'train/invoice-dataset/invoice_97.pdf',\n",
       "  'train/invoice-dataset/invoice_98.pdf',\n",
       "  'train/invoice-dataset/invoice_99.pdf',\n",
       "  'train/receipt-training/receipt_70.pdf',\n",
       "  'train/receipt-training/receipt_71.pdf',\n",
       "  'train/receipt-training/receipt_72.pdf',\n",
       "  'train/receipt-training/receipt_73.pdf',\n",
       "  'train/receipt-training/receipt_74.pdf',\n",
       "  'train/receipt-training/receipt_75.pdf',\n",
       "  'train/receipt-training/receipt_76.pdf',\n",
       "  'train/receipt-training/receipt_77.pdf',\n",
       "  'train/receipt-training/receipt_78.pdf',\n",
       "  'train/receipt-training/receipt_79.pdf',\n",
       "  'train/receipt-training/receipt_80.pdf',\n",
       "  'train/receipt-training/receipt_81.pdf',\n",
       "  'train/receipt-training/receipt_82.pdf',\n",
       "  'train/receipt-training/receipt_83.pdf',\n",
       "  'train/receipt-training/receipt_84.pdf',\n",
       "  'train/receipt-training/receipt_85.pdf',\n",
       "  'train/receipt-training/receipt_86.pdf',\n",
       "  'train/receipt-training/receipt_87.pdf',\n",
       "  'train/receipt-training/receipt_88.pdf',\n",
       "  'train/receipt-training/receipt_89.pdf'])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images=[]\n",
    "\n",
    "train_objects, names, train_images=get_s3_bucket_items(data_bucket, 'train', 'train/') \n",
    "images.append(train_images)\n",
    "\n",
    "\n",
    "if type(images[0]) is list:\n",
    "    images=[item for sublist in images for item in sublist]\n",
    "    \n",
    "names, images[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ad2f55",
   "metadata": {},
   "source": [
    "# Step 2: Extract text from sample documents using Amazon Textract <a id=\"step2\"></a>\n",
    "\n",
    "In this section we define local directories, and then use Amazon Textract's `detect_document_text` API to extract the raw text and geometry (bounding box) information for all the documents in S3. The extracted text and geometry information will be written into plaintext files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5fcb0573",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_prefix=os.getcwd()+'/textract_output/LINES/'\n",
    "box_prefix=os.getcwd()+'/textract_output/BBOX/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e27d1b",
   "metadata": {},
   "source": [
    "Utility function that uses Amazon Textract to extract text and writes to the defined directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "43fccc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### FUNCTION FOR EXTRACTING TEXT FROM EACH DOCUMENT AND STORING AS .TXT FILE FOR TRAIN LAYOUTLM USING TEXTRACT\n",
    "def textract_extract(table, bucket=data_bucket):        \n",
    "    try:\n",
    "        response = textract.detect_document_text(\n",
    "                Document={\n",
    "                    'S3Object': {\n",
    "                        'Bucket': bucket,\n",
    "                        'Name': table\n",
    "                    }\n",
    "                })    \n",
    "        a=[]\n",
    "        b=[]\n",
    "                # Print detected text\n",
    "        for item in response[\"Blocks\"]:\n",
    "\n",
    "            if item[\"BlockType\"] == \"LINE\":\n",
    "                a.append(item['Geometry']['BoundingBox'])\n",
    "                b.append(item[\"Text\"])\n",
    "\n",
    "        print(word_prefix)\n",
    "        print(os.path.dirname(table))\n",
    "        Path(word_prefix+os.path.dirname(table)).mkdir(parents=True, exist_ok=True)\n",
    "        Path(box_prefix+os.path.dirname(table)).mkdir(parents=True, exist_ok=True)\n",
    "        with open(word_prefix+table+'.txt', 'w', encoding=\"utf-8\") as f:\n",
    "            for item in b:\n",
    "                f.write(item+'\\n')\n",
    "        with open(box_prefix +table+'.txt', 'w', encoding=\"utf-8\") as p:\n",
    "            for item in a:\n",
    "                p.write(str(item)+'\\n')\n",
    "    except Exception as e:\n",
    "        print (e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4ceac7",
   "metadata": {},
   "source": [
    "Call the Textract function defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5318e2e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/invoice-dataset\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/invoice-dataset\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/invoice-dataset\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/invoice-dataset\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/invoice-dataset\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/invoice-dataset\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/invoice-dataset\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/invoice-dataset\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/invoice-dataset\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/invoice-dataset\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/invoice-dataset\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/invoice-dataset\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/invoice-dataset\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/invoice-dataset\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/invoice-dataset\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/invoice-dataset\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/invoice-dataset\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/invoice-dataset\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/invoice-dataset\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/invoice-dataset\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/invoice-dataset\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/train/invoice-dataset\n",
      "\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/invoice-dataset\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/invoice-dataset\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/invoice-dataset\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/invoice-dataset\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/invoice-dataset\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/invoice-dataset\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/invoice-dataset\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/receipt-training\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/receipt-training\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/invoice-dataset\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/receipt-training\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/receipt-training\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/receipt-training\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/receipt-training\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/receipt-training\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/receipt-training\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/receipt-training\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/receipt-training\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/receipt-training\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/receipt-training\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/receipt-training\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/receipt-training\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/receipt-training\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/receipt-training\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/receipt-training\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/receipt-training\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/receipt-training\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/receipt-training\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/receipt-training\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/receipt-training\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/receipt-training\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/receipt-training\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/receipt-training\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/receipt-training\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/receipt-training\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/receipt-training\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/receipt-training\n",
      "/home/ec2-user/SageMaker/Intelligent-Document-Processing-with-AWS-AI-ML-/chapter-2/textract_output/LINES/\n",
      "train/receipt-training\n"
     ]
    }
   ],
   "source": [
    "pool = mp.Pool(mp.cpu_count())\n",
    "pool.map(textract_extract, [table for table in images ])\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6cd778",
   "metadata": {},
   "source": [
    "# Step 3: Label the extracted data and prepare training dataset <a id=\"step3\"></a>\n",
    "\n",
    "Now that we have text extracted from our documents we will perform pre-processing of this data in order to train an [Amazon Comprehend custom classification model](https://docs.aws.amazon.com/comprehend/latest/dg/how-document-classification.html). Before we can train the custom classification model, we will need to label the data appropriately. For example, the invoice text should be labeled as \"invoice\" and receipt text labeled as \"Receipt\" and so on. This needs to be done for every document text extracted by Textract. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "108da238",
   "metadata": {},
   "outputs": [],
   "source": [
    "##lOOPING THRU THE DIRECTORY AND CREATING A DICT TO HOLD EACH TEXTRACT DOC PATH\n",
    "def data_path(path):    \n",
    "    \n",
    "    def listdir_nohidden(path):\n",
    "        for f in os.listdir(path):\n",
    "            if not f.startswith('.'):\n",
    "                yield f\n",
    "            \n",
    "    mapping={}\n",
    "    for i in names:   \n",
    "        print(i)\n",
    "        if os.path.isdir(path+i):\n",
    "            mapping[i] = sorted(listdir_nohidden(path+i))\n",
    "    # label or class or target list\n",
    "    label_compre = []\n",
    "    # text file data list\n",
    "    text_compre = []\n",
    "\n",
    "    # unpacking and iterating through dictionary\n",
    "    for i, j in mapping.items():\n",
    "        \n",
    "        # iterating through list of files for each class\n",
    "        for k in j:\n",
    "            # appending labels/class/target\n",
    "            label_compre.append(i)\n",
    "            # reading the file and appending to data list\n",
    "            text_compre.append(open(path+i+\"/\"+k, encoding=\"utf-8\").read().replace('\\n',' '))\n",
    "    return label_compre, text_compre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065a8493",
   "metadata": {},
   "source": [
    " We can now call the function to label data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b7121ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "receipt-training\n",
      "invoice-dataset\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>Invoice #: 96835747-6 INVOICE Created: Dec 09,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>INVOICE Invoice #: 24315125-2 Created: Jul 30,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>Invoice #: 14513247-9 INVOICE Created: Aug 29,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>INVOICE Invoice #: 27151918-4 Created: Jul 17,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>Invoice #: 62039380-0 INVOICE Created: Mar 02,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>INVOICE Invoice #: 52038819-2 Created: Feb 06,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>Invoice #: 19182552-7 INVOICE Created: Jan 15,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>INVOICE Invoice #: 19311213-7 Created: Apr 25,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>Invoice #: 25570951-8 INVOICE Created: Jun 21,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>INVOICE Invoice #: 82477191-k Created: Jun 20,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>INVOICE Invoice #: 24203416-3 Created: Apr 20,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>Invoice #: 15733370-4 INVOICE Created: May 05,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>INVOICE Invoice #: 49973360-7 Created: Jun 08,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>Invoice #: 32674511-1 INVOICE Created: Oct 26,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>INVOICE Invoice #: 70387625-0 Created: Apr 12,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>Invoice #: 81401851-2 INVOICE Created: Sep 19,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>INVOICE Invoice #: 66522185-7 Created: Jul 09,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>Invoice #: 72200901-0 INVOICE Created: Nov 14,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>INVOICE Invoice #: 16430087-0 Created: Mar 10,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>Invoice #: 74022898-6 INVOICE Created: Nov 13,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>Invoice #: 10368678-4 INVOICE Created: Nov 13,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>INVOICE Invoice #: 89031604-2 Created: Apr 26,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>Invoice #: 76335807-0 INVOICE Created: Jan 20,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>INVOICE Invoice #: 53940008-8 Created: Sep 08,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>Invoice #: 29584719-0 INVOICE Created: Jul 02,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>INVOICE Invoice #: 61309087-8 Created: Apr 25,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>Invoice #: 77169086-6 INVOICE Created: Nov 17,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>INVOICE Invoice #: 33982623-4 Created: Nov 08,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>Invoice #: 10562992-3 INVOICE Created: Oct 01,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>INVOICE Invoice #: 98082211-7 Created: Aug 05,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               label                                           document\n",
       "0   receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "1   receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "2   receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "3   receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "4   receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "5   receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "6   receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "7   receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "8   receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "9   receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "10  receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "11  receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "12  receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "13  receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "14  receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "15  receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "16  receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "17  receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "18  receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "19  receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "20  receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "21  receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "22  receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "23  receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "24  receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "25  receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "26  receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "27  receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "28  receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "29  receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "30   invoice-dataset  Invoice #: 96835747-6 INVOICE Created: Dec 09,...\n",
       "31   invoice-dataset  INVOICE Invoice #: 24315125-2 Created: Jul 30,...\n",
       "32   invoice-dataset  Invoice #: 14513247-9 INVOICE Created: Aug 29,...\n",
       "33   invoice-dataset  INVOICE Invoice #: 27151918-4 Created: Jul 17,...\n",
       "34   invoice-dataset  Invoice #: 62039380-0 INVOICE Created: Mar 02,...\n",
       "35   invoice-dataset  INVOICE Invoice #: 52038819-2 Created: Feb 06,...\n",
       "36   invoice-dataset  Invoice #: 19182552-7 INVOICE Created: Jan 15,...\n",
       "37   invoice-dataset  INVOICE Invoice #: 19311213-7 Created: Apr 25,...\n",
       "38   invoice-dataset  Invoice #: 25570951-8 INVOICE Created: Jun 21,...\n",
       "39   invoice-dataset  INVOICE Invoice #: 82477191-k Created: Jun 20,...\n",
       "40   invoice-dataset  INVOICE Invoice #: 24203416-3 Created: Apr 20,...\n",
       "41   invoice-dataset  Invoice #: 15733370-4 INVOICE Created: May 05,...\n",
       "42   invoice-dataset  INVOICE Invoice #: 49973360-7 Created: Jun 08,...\n",
       "43   invoice-dataset  Invoice #: 32674511-1 INVOICE Created: Oct 26,...\n",
       "44   invoice-dataset  INVOICE Invoice #: 70387625-0 Created: Apr 12,...\n",
       "45   invoice-dataset  Invoice #: 81401851-2 INVOICE Created: Sep 19,...\n",
       "46   invoice-dataset  INVOICE Invoice #: 66522185-7 Created: Jul 09,...\n",
       "47   invoice-dataset  Invoice #: 72200901-0 INVOICE Created: Nov 14,...\n",
       "48   invoice-dataset  INVOICE Invoice #: 16430087-0 Created: Mar 10,...\n",
       "49   invoice-dataset  Invoice #: 74022898-6 INVOICE Created: Nov 13,...\n",
       "50   invoice-dataset  Invoice #: 10368678-4 INVOICE Created: Nov 13,...\n",
       "51   invoice-dataset  INVOICE Invoice #: 89031604-2 Created: Apr 26,...\n",
       "52   invoice-dataset  Invoice #: 76335807-0 INVOICE Created: Jan 20,...\n",
       "53   invoice-dataset  INVOICE Invoice #: 53940008-8 Created: Sep 08,...\n",
       "54   invoice-dataset  Invoice #: 29584719-0 INVOICE Created: Jul 02,...\n",
       "55   invoice-dataset  INVOICE Invoice #: 61309087-8 Created: Apr 25,...\n",
       "56   invoice-dataset  Invoice #: 77169086-6 INVOICE Created: Nov 17,...\n",
       "57   invoice-dataset  INVOICE Invoice #: 33982623-4 Created: Nov 08,...\n",
       "58   invoice-dataset  Invoice #: 10562992-3 INVOICE Created: Oct 01,...\n",
       "59   invoice-dataset  INVOICE Invoice #: 98082211-7 Created: Aug 05,..."
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_compre, text_compre=[],[]\n",
    "\n",
    "path=word_prefix+'train/'\n",
    "label_compre_train, text_compre_train=data_path(path)\n",
    "label_compre.append(label_compre_train)\n",
    "text_compre.append(text_compre_train)\n",
    "\n",
    "if type(label_compre[0]) is list:\n",
    "    label_compre=[item for sublist in label_compre for item in sublist]\n",
    "    text_compre=[item for sublist in text_compre for item in sublist]\n",
    "\n",
    "data_compre= pd.DataFrame()\n",
    "data_compre[\"label\"] =label_compre   \n",
    "data_compre[\"document\"] = text_compre\n",
    "data_compre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb5f399",
   "metadata": {},
   "source": [
    "# Step 4: Create Amazon Comprehend Classification training job <a id=\"step4\"></a>\n",
    "\n",
    "Once we have a labeled dataset ready we are going to create and train a [Amazon Comprehend custom classification model](https://docs.aws.amazon.com/comprehend/latest/dg/how-document-classification.html) with the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "73f4f1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload Comprehend training data to S3\n",
    "\n",
    "key='idp/comprehend/comprehend_train_data.csv'\n",
    "\n",
    "data_compre.to_csv(\"comprehend_train_data.csv\", index=False, header=False)\n",
    "s3.upload_file(Filename='comprehend_train_data.csv', \n",
    "               Bucket=data_bucket, \n",
    "               Key=key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ac5c2a",
   "metadata": {},
   "source": [
    "### Create Amazon Comprehend custom classification Training Job\n",
    "\n",
    "We will use Amazon Comprehend's Custom Classification to train our own model for classifying the documents. We will use Amazon Comprehend `CreateDocumentClassifier` API to create a classifier which will train a custom model using the labeled data CSV file we created above. The training data contains extracted text, that was extracted using Amazon Textract, and then labeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "aa62cb16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-044573436347/idp/comprehend/comprehend_train_data.csv'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f's3://{data_bucket}/{key}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8a3ed358",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DocumentClassifierArn': 'arn:aws:comprehend:us-east-1:044573436347:document-classifier/Doc-Classifier-IDP/version/v4', 'ResponseMetadata': {'RequestId': '5928af78-8f69-4023-813e-d2e116967fd0', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '5928af78-8f69-4023-813e-d2e116967fd0', 'content-type': 'application/x-amz-json-1.1', 'content-length': '119', 'date': 'Fri, 23 Sep 2022 04:01:42 GMT'}, 'RetryAttempts': 0}}\n",
      "Comprehend Custom Classifier created with ARN: arn:aws:comprehend:us-east-1:044573436347:document-classifier/Doc-Classifier-IDP/version/v4\n"
     ]
    }
   ],
   "source": [
    "# Create a document classifier\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "id = str(datetime.datetime.now().strftime(\"%s\"))\n",
    "\n",
    "document_classifier_name = 'Doc-Classifier-IDP'\n",
    "document_classifier_version = 'v4'\n",
    "document_classifier_arn = ''\n",
    "response = None\n",
    "\n",
    "\n",
    "create_response = comprehend.create_document_classifier(\n",
    "        InputDataConfig={\n",
    "            'DataFormat': 'COMPREHEND_CSV',\n",
    "            'S3Uri': f's3://{data_bucket}/{key}'\n",
    "        },\n",
    "        DataAccessRoleArn=role,\n",
    "        DocumentClassifierName=document_classifier_name,\n",
    "        VersionName=document_classifier_version,\n",
    "        LanguageCode='en',\n",
    "        Mode='MULTI_CLASS'\n",
    ")\n",
    "print(create_response)\n",
    "document_classifier_arn = create_response['DocumentClassifierArn']\n",
    "    \n",
    "print(f\"Comprehend Custom Classifier created with ARN: {document_classifier_arn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c3a8d8",
   "metadata": {},
   "source": [
    "This job can take ~30 minutes to complete. Once the training job is completed move on to next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e9a9f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
