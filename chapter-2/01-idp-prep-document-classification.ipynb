{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12c88e5e",
   "metadata": {},
   "source": [
    "# Intelligent Document Processing Classification\n",
    "\n",
    "Documents contain valuable information and come in various shapes and forms. In most cases, you are manually processing these documents which is time consuming, prone to error, and costly. Not only do you want this information extracted quickly but can also automate business processes that presently relies on manual inputs and intervention across various file types and formats.\n",
    "\n",
    "To help you overcome these challenges, AWS Machine Learning (ML) now provides you choices when it comes to extracting information from complex content in any document format such as insurance claims, mortgages, healthcare claims, contracts, and legal contracts.\n",
    "\n",
    "The architecture below is a sample use case which involves these phases of an Intelligent document processing workflow - starting with extracting text from documents, training a custom classifier to classify our documents, training a custom name entity recognizer to extract custom entities from the documents, and finally perform document enrichment such as redaction and extract other details from the document.\n",
    "\n",
    "<img src=\"book-classification.png\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa87421",
   "metadata": {},
   "source": [
    "# Prepare for Document Classification\n",
    "In this lab we will walk you through an hands-on lab on document classification using Amazon Comprehend\n",
    "Custom Classifier. We will use Amazon Textract to first extract the text out of our documents and then label them and then use the data for training our Amazon comprehend custom classifier.\n",
    "\n",
    "In this notebook we will - \n",
    "\n",
    "- [Step 1: Setup notebook and upload sample documents to Amazon S3](#step1)\n",
    "- [Step 2: Extract text from sample documents using Amazon Textract](#step2)\n",
    "- [Step 3: Label the extracted data and prepare a CSV training dataset](#step3)\n",
    "- [Step 4: Create Amazon Comprehend Classification training job](#step4)\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1064cfec",
   "metadata": {},
   "source": [
    "# Step 1: Setup notebook and upload  sample documents to Amazon S3 <a id=\"step1\"></a>\n",
    "\n",
    "In this step, we will import some necessary libraries that will be used throughout this notebook. We will then upload all the documents from the `/classification-training-dataset` folder to SageMaker's default bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6affcf6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textract-trp in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (0.1.3)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install textract-trp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67891a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker role is: arn:aws:iam::044573436347:role/text-cm-SagemakerRole-SXXWU3NUWVCX\n",
      "Default SageMaker Bucket: s3://sagemaker-us-east-1-044573436347\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import botocore\n",
    "import sagemaker\n",
    "import time\n",
    "import os\n",
    "import os.path\n",
    "import json\n",
    "import datetime\n",
    "import io\n",
    "import uuid\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pytz import timezone\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import multiprocessing as mp\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Document\n",
    "from pprint import pprint\n",
    "from IPython.display import Image, display, HTML, JSON, IFrame\n",
    "from PIL import Image as PImage, ImageDraw\n",
    "\n",
    "\n",
    "# variables\n",
    "data_bucket = sagemaker.Session().default_bucket()\n",
    "region = boto3.session.Session().region_name\n",
    "\n",
    "os.environ[\"BUCKET\"] = data_bucket\n",
    "os.environ[\"REGION\"] = region\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "print(f\"SageMaker role is: {role}\\nDefault SageMaker Bucket: s3://{data_bucket}\")\n",
    "\n",
    "s3=boto3.client('s3')\n",
    "textract = boto3.client('textract', region_name=region)\n",
    "comprehend=boto3.client('comprehend', region_name=region)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d9fb4c",
   "metadata": {},
   "source": [
    "### Upload sample data to S3 bucket\n",
    "\n",
    "The sample documents are in `/classification-training` directory. For this workshop, we will be using sample paystubs, bank statements, and receipts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "820544a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Upload images to S3 bucket:\n",
    "!aws s3 cp classification-training-dataset s3://{data_bucket}/idp/textract --recursive --only-show-errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040c1e9f",
   "metadata": {},
   "source": [
    "# Step 2: Extract text from sample documents using Amazon Textract <a id=\"step2\"></a>\n",
    "\n",
    "In this section we define local directories, and then use Amazon Textract's `detect_document_text` API to extract the raw text and geometry (bounding box) information for all the documents in S3. The extracted text and geometry information will be written into plaintext files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f3911e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_prefix=os.getcwd()+'/textract_output/LINES/'\n",
    "box_prefix=os.getcwd()+'/textract_output/BBOX/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251499ce",
   "metadata": {},
   "source": [
    "Utility function that uses Amazon Textract to extract text and writes to the defined directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ca57e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### FUNCTION FOR EXTRACTING TEXT FROM EACH DOCUMENT AND STORING AS .TXT FILE FOR TRAIN LAYOUTLM USING TEXTRACT\n",
    "def textract_extract(table, bucket=data_bucket):        \n",
    "    try:\n",
    "        response = textract.detect_document_text(\n",
    "                Document={\n",
    "                    'S3Object': {\n",
    "                        'Bucket': bucket,\n",
    "                        'Name': table\n",
    "                    }\n",
    "                })    \n",
    "        a=[]\n",
    "        b=[]\n",
    "                # Print detected text\n",
    "        for item in response[\"Blocks\"]:\n",
    "\n",
    "            if item[\"BlockType\"] == \"LINE\":\n",
    "                a.append(item['Geometry']['BoundingBox'])\n",
    "                b.append(item[\"Text\"])\n",
    "\n",
    "        print(word_prefix)\n",
    "        print(os.path.dirname(table))\n",
    "        Path(word_prefix+os.path.dirname(table)).mkdir(parents=True, exist_ok=True)\n",
    "        Path(box_prefix+os.path.dirname(table)).mkdir(parents=True, exist_ok=True)\n",
    "        with open(word_prefix+table+'.txt', 'w', encoding=\"utf-8\") as f:\n",
    "            for item in b:\n",
    "                f.write(item+'\\n')\n",
    "        with open(box_prefix +table+'.txt', 'w', encoding=\"utf-8\") as p:\n",
    "            for item in a:\n",
    "                p.write(str(item)+'\\n')\n",
    "    except Exception as e:\n",
    "        print (e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2197ebce",
   "metadata": {},
   "source": [
    "Call the Textract function defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "864d9602",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/invoice-dataset\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/invoice-dataset\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/invoice-dataset\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/invoice-dataset\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/invoice-dataset\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/invoice-dataset\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/invoice-dataset\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/invoice-dataset\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/invoice-dataset\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/invoice-dataset\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/invoice-dataset\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/invoice-dataset\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/invoice-dataset\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/invoice-dataset\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/invoice-dataset\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/invoice-dataset\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/invoice-dataset\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/invoice-dataset\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/invoice-dataset\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/invoice-dataset\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/invoice-dataset\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/invoice-dataset\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/invoice-dataset\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/invoice-dataset\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/invoice-dataset\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/invoice-dataset\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/invoice-dataset\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/invoice-dataset\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/invoice-dataset\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/receipt-training\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/invoice-dataset\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/receipt-training\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/receipt-training\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/receipt-training\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/receipt-training\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/receipt-training\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/receipt-training\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/receipt-training\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/receipt-training\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/receipt-training\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/receipt-training\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/receipt-training\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/receipt-training\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/receipt-training\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/receipt-training\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/receipt-training\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/receipt-training\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/receipt-training\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/receipt-training\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/receipt-training\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/receipt-training\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/receipt-training\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/receipt-training\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/receipt-training\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/receipt-training\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/receipt-training\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/receipt-training\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/receipt-training\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/receipt-training\n",
      "/home/ec2-user/SageMaker/textract_output/LINES/\n",
      "idp/textract/receipt-training\n"
     ]
    }
   ],
   "source": [
    "pool = mp.Pool(mp.cpu_count())\n",
    "pool.map(textract_extract, [table for table in images ])\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e69f39",
   "metadata": {},
   "source": [
    "# Step 3: Label the extracted data and prepare training dataset <a id=\"step3\"></a>\n",
    "\n",
    "Now that we have text extracted from our documents we will perform pre-processing of this data in order to train an [Amazon Comprehend custom classification model](https://docs.aws.amazon.com/comprehend/latest/dg/how-document-classification.html). Before we can train the custom classification model, we will need to label the data appropriately. For example, the invoice text should be labeled as \"invoice\" and receipt text labeled as \"Receipt\" and so on. This needs to be done for every document text extracted by Textract. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ece20ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "##lOOPING THRU THE DIRECTORY AND CREATING A DICT TO HOLD EACH TEXTRACT DOC PATH\n",
    "def data_path(path):    \n",
    "    \n",
    "    def listdir_nohidden(path):\n",
    "        for f in os.listdir(path):\n",
    "            if not f.startswith('.'):\n",
    "                yield f\n",
    "            \n",
    "    mapping={}\n",
    "    for i in names:        \n",
    "        if os.path.isdir(path+i):\n",
    "            mapping[i] = sorted(listdir_nohidden(path+i))\n",
    "    # label or class or target list\n",
    "    label_compre = []\n",
    "    # text file data list\n",
    "    text_compre = []\n",
    "\n",
    "    # unpacking and iterating through dictionary\n",
    "    for i, j in mapping.items():\n",
    "        # iterating through list of files for each class\n",
    "        for k in j:\n",
    "            # appending labels/class/target\n",
    "            label_compre.append(i)\n",
    "            # reading the file and appending to data list\n",
    "            text_compre.append(open(path+i+\"/\"+k, encoding=\"utf-8\").read().replace('\\n',' '))\n",
    "    return label_compre, text_compre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33787c73",
   "metadata": {},
   "source": [
    " We can now call the function to label data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a58c659e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>receipt-training</td>\n",
       "      <td>THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>Invoice #: 96835747-6 INVOICE Created: Dec 09,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>Invoice #: 24315125-2 INVOICE Created: Jul 30,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>Invoice #: 14513247-9 INVOICE Created: Aug 29,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>Invoice #: 27151918-4 INVOICE Created: Jul 17,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>Invoice #: 62039380-0 INVOICE Created: Mar 02,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>Invoice #: 52038819-2 INVOICE Created: Feb 06,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>Invoice #: 19182552-7 INVOICE Created: Jan 15,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>Invoice #: 19311213-7 INVOICE Created: Apr 25,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>Invoice #: 25570951-8 INVOICE Created: Jun 21,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>Invoice #: 82477191-k INVOICE Created: Jun 20,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>Invoice #: 24203416-3 INVOICE Created: Apr 20,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>Invoice #: 15733370-4 INVOICE Created: May 05,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>Invoice #: 49973360-7 INVOICE Created: Jun 08,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>Invoice #: 32674511-1 INVOICE Created: Oct 26,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>Invoice #: 70387625-0 INVOICE Created: Apr 12,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>Invoice #: 81401851-2 INVOICE Created: Sep 19,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>Invoice #: 66522185-7 INVOICE Created: Jul 09,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>Invoice #: 72200901-0 INVOICE Created: Nov 14,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>Invoice #: 16430087-0 INVOICE Created: Mar 10,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>Invoice #: 74022898-6 INVOICE Created: Nov 13,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>Invoice #: 10368678-4 INVOICE Created: Nov 13,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>invoice #: 89031604-2 INVOICE Created: Apr 26,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>Invoice #: 76335807-0 INVOICE Created: Jan 20,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>Invoice #: 53940008-8 INVOICE Created: Sep 08,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>Invoice #: 29584719-0 INVOICE Created: Jul 02,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>Invoice #: 61309087-8 INVOICE Created: Apr 25,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>Invoice #: 77169086-6 INVOICE Created: Nov 17,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>Invoice #: 33982623-4 INVOICE Created: Nov 08,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>Invoice #: 10562992-3 INVOICE Created: Oct 01,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>invoice-dataset</td>\n",
       "      <td>Invoice #: 98082211-7 INVOICE Created: Aug 05,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               label                                           document\n",
       "0   receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "1   receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "2   receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "3   receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "4   receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "5   receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "6   receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "7   receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "8   receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "9   receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "10  receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "11  receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "12  receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "13  receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "14  receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "15  receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "16  receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "17  receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "18  receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "19  receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "20  receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "21  receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "22  receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "23  receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "24  receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "25  receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "26  receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "27  receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "28  receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "29  receipt-training  THE AIML StORE 1234 SOMEWHERE RD POWAY, CALIFO...\n",
       "30   invoice-dataset  Invoice #: 96835747-6 INVOICE Created: Dec 09,...\n",
       "31   invoice-dataset  Invoice #: 24315125-2 INVOICE Created: Jul 30,...\n",
       "32   invoice-dataset  Invoice #: 14513247-9 INVOICE Created: Aug 29,...\n",
       "33   invoice-dataset  Invoice #: 27151918-4 INVOICE Created: Jul 17,...\n",
       "34   invoice-dataset  Invoice #: 62039380-0 INVOICE Created: Mar 02,...\n",
       "35   invoice-dataset  Invoice #: 52038819-2 INVOICE Created: Feb 06,...\n",
       "36   invoice-dataset  Invoice #: 19182552-7 INVOICE Created: Jan 15,...\n",
       "37   invoice-dataset  Invoice #: 19311213-7 INVOICE Created: Apr 25,...\n",
       "38   invoice-dataset  Invoice #: 25570951-8 INVOICE Created: Jun 21,...\n",
       "39   invoice-dataset  Invoice #: 82477191-k INVOICE Created: Jun 20,...\n",
       "40   invoice-dataset  Invoice #: 24203416-3 INVOICE Created: Apr 20,...\n",
       "41   invoice-dataset  Invoice #: 15733370-4 INVOICE Created: May 05,...\n",
       "42   invoice-dataset  Invoice #: 49973360-7 INVOICE Created: Jun 08,...\n",
       "43   invoice-dataset  Invoice #: 32674511-1 INVOICE Created: Oct 26,...\n",
       "44   invoice-dataset  Invoice #: 70387625-0 INVOICE Created: Apr 12,...\n",
       "45   invoice-dataset  Invoice #: 81401851-2 INVOICE Created: Sep 19,...\n",
       "46   invoice-dataset  Invoice #: 66522185-7 INVOICE Created: Jul 09,...\n",
       "47   invoice-dataset  Invoice #: 72200901-0 INVOICE Created: Nov 14,...\n",
       "48   invoice-dataset  Invoice #: 16430087-0 INVOICE Created: Mar 10,...\n",
       "49   invoice-dataset  Invoice #: 74022898-6 INVOICE Created: Nov 13,...\n",
       "50   invoice-dataset  Invoice #: 10368678-4 INVOICE Created: Nov 13,...\n",
       "51   invoice-dataset  invoice #: 89031604-2 INVOICE Created: Apr 26,...\n",
       "52   invoice-dataset  Invoice #: 76335807-0 INVOICE Created: Jan 20,...\n",
       "53   invoice-dataset  Invoice #: 53940008-8 INVOICE Created: Sep 08,...\n",
       "54   invoice-dataset  Invoice #: 29584719-0 INVOICE Created: Jul 02,...\n",
       "55   invoice-dataset  Invoice #: 61309087-8 INVOICE Created: Apr 25,...\n",
       "56   invoice-dataset  Invoice #: 77169086-6 INVOICE Created: Nov 17,...\n",
       "57   invoice-dataset  Invoice #: 33982623-4 INVOICE Created: Nov 08,...\n",
       "58   invoice-dataset  Invoice #: 10562992-3 INVOICE Created: Oct 01,...\n",
       "59   invoice-dataset  Invoice #: 98082211-7 INVOICE Created: Aug 05,..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_compre, text_compre=[],[]\n",
    "\n",
    "path=word_prefix+'idp/textract/'\n",
    "label_compre_train, text_compre_train=data_path(path)\n",
    "label_compre.append(label_compre_train)\n",
    "text_compre.append(text_compre_train)\n",
    "\n",
    "if type(label_compre[0]) is list:\n",
    "    label_compre=[item for sublist in label_compre for item in sublist]\n",
    "    text_compre=[item for sublist in text_compre for item in sublist]\n",
    "\n",
    "data_compre= pd.DataFrame()\n",
    "data_compre[\"label\"] =label_compre   \n",
    "data_compre[\"document\"] = text_compre\n",
    "data_compre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760bd980",
   "metadata": {},
   "source": [
    "# Step 4: Create Amazon Comprehend Classification training job <a id=\"step4\"></a>\n",
    "\n",
    "Once we have a labeled dataset ready we are going to create and train a [Amazon Comprehend custom classification model](https://docs.aws.amazon.com/comprehend/latest/dg/how-document-classification.html) with the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1c464d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload Comprehend training data to S3\n",
    "\n",
    "key='idp/comprehend/comprehend_train_data.csv'\n",
    "\n",
    "data_compre.to_csv(\"comprehend_train_data.csv\", index=False, header=False)\n",
    "s3.upload_file(Filename='comprehend_train_data.csv', \n",
    "               Bucket=data_bucket, \n",
    "               Key=key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d500b2c",
   "metadata": {},
   "source": [
    "### Create Amazon Comprehend custom classification Training Job\n",
    "\n",
    "We will use Amazon Comprehend's Custom Classification to train our own model for classifying the documents. We will use Amazon Comprehend `CreateDocumentClassifier` API to create a classifier which will train a custom model using the labeled data CSV file we created above. The training data contains extracted text, that was extracted using Amazon Textract, and then labeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39a66dc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-044573436347/idp/comprehend/comprehend_train_data.csv'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f's3://{data_bucket}/{key}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e0a140f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comprehend Custom Classifier created with ARN: arn:aws:comprehend:us-east-1:044573436347:document-classifier/Sample-Doc-Classifier-IDP/version/Sample-Doc-Classifier-IDP-v1\n"
     ]
    }
   ],
   "source": [
    "# Create a document classifier\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "id = str(datetime.datetime.now().strftime(\"%s\"))\n",
    "\n",
    "document_classifier_name = 'Doc-Classifier-IDP'\n",
    "document_classifier_version = 'v1'\n",
    "document_classifier_arn = ''\n",
    "response = None\n",
    "\n",
    "try:\n",
    "    create_response = comprehend.create_document_classifier(\n",
    "        InputDataConfig={\n",
    "            'DataFormat': 'COMPREHEND_CSV',\n",
    "            'S3Uri': f's3://{data_bucket}/{key}'\n",
    "        },\n",
    "        DataAccessRoleArn=role,\n",
    "        DocumentClassifierName=document_classifier_name,\n",
    "        VersionName=document_classifier_version,\n",
    "        LanguageCode='en',\n",
    "        Mode='MULTI_CLASS'\n",
    "    )\n",
    "    \n",
    "    document_classifier_arn = create_response['DocumentClassifierArn']\n",
    "    \n",
    "    print(f\"Comprehend Custom Classifier created with ARN: {document_classifier_arn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d06d15f",
   "metadata": {},
   "source": [
    "This job can take ~30 minutes to complete. Once the training job is completed move on to next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0d0280",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
